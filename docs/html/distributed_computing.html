<!DOCTYPE html> <html lang=en > <meta charset=utf-8  /> <meta name=viewport  content="width=device-width, initial-scale=1.0" /><meta name=generator  content="Docutils 0.19: https://docutils.sourceforge.io/" /> <meta name=viewport  content="width=device-width,initial-scale=1"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name="lang:clipboard.copy" content="Copy to clipboard"> <meta name="lang:clipboard.copied" content="Copied to clipboard"> <meta name="lang:search.language" content=en > <meta name="lang:search.pipeline.stopwords" content=True > <meta name="lang:search.pipeline.trimmer" content=True > <meta name="lang:search.result.none" content="No matching documents"> <meta name="lang:search.result.one" content="1 matching document"> <meta name="lang:search.result.other" content="# matching documents"> <meta name="lang:search.tokenizer" content="[\s\-]+"> <link href="https://fonts.gstatic.com/" rel=preconnect  crossorigin> <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel=stylesheet > <style> body, input { font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif } code, kbd, pre { font-family: "Roboto Mono", "Courier New", Courier, monospace } </style> <link rel=stylesheet  href="_static/stylesheets/application.css"/> <link rel=stylesheet  href="_static/stylesheets/application-palette.css"/> <link rel=stylesheet  href="_static/stylesheets/application-fixes.css"/> <link rel=stylesheet  href="_static/fonts/material-icons.css"/> <meta name=theme-color  content="#2196f3"> <script src="_static/javascripts/modernizr.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XX133829453-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'UA-XX133829453-1'); </script> <title>Distributed Computing with dask &#8212; Practical Data Science</title> <link rel=stylesheet  type="text/css" href="_static/pygments.css" /> <link rel=stylesheet  type="text/css" href="_static/material.css" /> <script data-url_root="./" id=documentation_options  src="_static/documentation_options.js"></script> <script src="_static/jquery.js"></script> <script src="_static/underscore.js"></script> <script src="_static/_sphinx_javascript_frameworks_compat.js"></script> <script src="_static/doctools.js"></script> <script src="_static/sphinx_highlight.js"></script> <script crossorigin=anonymous  integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script> <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script> <script defer=defer  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <link rel="shortcut icon" href="_static/mids_logo.svg"/> <link rel=index  title=Index  href=genindex.html  /> <link rel=search  title=Search  href=search.html  /> <link rel=next  title="Git and Github" href=git_and_github.html  /> <link rel=prev  title="Parallel Computing" href=parallelism.html  /> <body dir=ltr data-md-color-primary=blue-grey data-md-color-accent=blue> <svg class=md-svg > <defs data-children-count=0 > <svg xmlns="http://www.w3.org/2000/svg" width=416  height=448  viewBox="0 0 416 448" id=__github ><path fill=currentColor  d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle  data-md-toggle=drawer  type=checkbox  id=__drawer > <input class=md-toggle  data-md-toggle=search  type=checkbox  id=__search > <label class=md-overlay  data-md-component=overlay  for=__drawer ></label> <a href="#distributed_computing" tabindex=1  class=md-skip > Skip to content </a> <header class=md-header  data-md-component=header > <nav class="md-header-nav md-grid"> <div class="md-flex navheader"> <div class="md-flex__cell md-flex__cell--shrink"> <a href=index.html  title="Practical Data Science" class="md-header-nav__button md-logo"> <img src="_static/mids_logo.svg" height=26  alt="Practical Data Science logo"> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer ></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title > <span class=md-header-nav__topic >Practical Data Science</span> <span class=md-header-nav__topic > Distributed Computing with dask </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search ></label> <div class=md-search  data-md-component=search  role=dialog > <label class=md-search__overlay  for=__search ></label> <div class=md-search__inner  role=search > <form class=md-search__form  action=search.html  method=get  name=search > <input type=text  class=md-search__input  name=q  placeholder=Search  autocapitalize=off  autocomplete=off  spellcheck=false  data-md-component=query  data-md-state=active > <label class="md-icon md-search__icon" for=__search ></label> <button type=reset  class="md-icon md-search__icon" data-md-component=reset  tabindex=-1 > &#xE5CD; </button> </form> <div class=md-search__output > <div class=md-search__scrollwrap  data-md-scrollfix> <div class=md-search-result  data-md-component=result > <div class=md-search-result__meta > Type to start searching </div> <ol class=md-search-result__list ></ol> </div> </div> </div> </div> </div> </div> <script src="_static/javascripts/version_dropdown.js"></script> <script> var json_loc = ""versions.json"", target_loc = "../", text = "Versions"; $( document ).ready( add_version_dropdown(json_loc, target_loc, text)); </script> </div> </nav> </header> <div class=md-container > <nav class=md-tabs  data-md-component=tabs > <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list > <li class=md-tabs__item ><a href=index.html  class=md-tabs__link >Home</a> <li class=md-tabs__item ><a href=class_schedule.html  class=md-tabs__link >Class Schedule</a> <li class=md-tabs__item ><a href=topic_list.html  class=md-tabs__link >Topic List</a> <li class=md-tabs__item ><a href="https://www.nickeubank.com" class=md-tabs__link >About The Author</a> </ul> </div> </nav> <main class=md-main > <div class="md-main__inner md-grid" data-md-component=container > <div class="md-sidebar md-sidebar--primary" data-md-component=navigation > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--primary" data-md-level=0 > <label class="md-nav__title md-nav__title--site" for=__drawer > <a href=index.html  title="Practical Data Science" class="md-nav__button md-logo"> <img src="_static/mids_logo.svg" alt=" logo" width=48  height=48 > </a> <a href=index.html  title="Practical Data Science">Practical Data Science</a> </label> <ul class=md-nav__list > <li class=md-nav__item > <a href=class_schedule.html  class=md-nav__link >Class Schedule</a> <li class=md-nav__item > <a href=autograder_guidelines.html  class=md-nav__link >Autograder Guidelines</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Environment Setup</span></span> <li class=md-nav__item > <a href=setup_python.html  class=md-nav__link >Setup Python and miniconda</a> <li class=md-nav__item > <a href=setup_vscode.html  class=md-nav__link >Setup VS Code</a> <li class=md-nav__item > <a href=setup_augmented_commandline.html  class=md-nav__link >Setup Command Line</a> <li class=md-nav__item > <a href=jupyter.html  class=md-nav__link >Setup Jupyter</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Basic Tools</span></span> <li class=md-nav__item > <a href=command_line_part1.html  class=md-nav__link >Command Line, Basics</a> <li class=md-nav__item > <a href=command_line_part2.html  class=md-nav__link >Command Line, Advanced</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Python &amp; Pandas</span></span> <li class=md-nav__item > <a href=python_v_r.html  class=md-nav__link >Python / R Differences</a> <li class=md-nav__item > <a href=vars_v_objects.html  class=md-nav__link >Python: Vars v Objects</a> <li class=md-nav__item > <a href=ints_and_floats.html  class=md-nav__link >Numbers in Computers</a> <li class=md-nav__item > <a href=pandas_series.html  class=md-nav__link >Pandas 1: Series</a> <li class=md-nav__item > <a href=plotting_altair_part1.html  class=md-nav__link >Plotting, Basics</a> <li class=md-nav__item > <a href=plotting_altair_part2.html  class=md-nav__link >Plotting, Advanced</a> <li class=md-nav__item > <a href=views_and_copies_in_pandas.html  class=md-nav__link >Pandas 3: Views</a> <li class=md-nav__item > <a href=parquet.html  class=md-nav__link >Parquet Format</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >DS Concepts</span></span> <li class=md-nav__item > <a href=defensive_programming.html  class=md-nav__link >Defensive Programming</a> <li class=md-nav__item > <a href=workflow.html  class=md-nav__link >Workflow Management</a> <li class=md-nav__item > <a href=backwards_design.html  class=md-nav__link >Backwards Design</a> <li class=md-nav__item > <a href=getting_help.html  class=md-nav__link >Getting Help Online</a> <li class=md-nav__item > <a href=what_is_big_data.html  class=md-nav__link >What is Big Data?</a> <li class=md-nav__item > <a href=big_data_strategies.html  class=md-nav__link >Working with Big Data</a> <li class=md-nav__item > <a href=performance_understanding.html  class=md-nav__link >Understanding Performance</a> <li class=md-nav__item > <a href=performance_solutions.html  class=md-nav__link >Solving Performance Probs</a> <li class=md-nav__item > <a href=parallelism.html  class=md-nav__link >Parallel Computing</a> <li class=md-nav__item > <input class="md-toggle md-nav__toggle" data-md-toggle=toc  type=checkbox  id=__toc > <label class="md-nav__link md-nav__link--active" for=__toc > Distributed Computing </label> <a href="#" class="md-nav__link md-nav__link--active">Distributed Computing</a> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >Contents</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#distributed-computing--page-root" class=md-nav__link >Distributed Computing with dask</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#What-can-dask-do-for-me?" class=md-nav__link >What can dask do for me?</a> <li class=md-nav__item ><a href="#“Um…-why-didn’t-you-tell-us-about-this-before?”-I-hear-you-say…" class=md-nav__link >“Um… why didn’t you tell us about this before?” I hear you say…</a> <li class=md-nav__item ><a href="#Vocabulary" class=md-nav__link >Vocabulary</a> <li class=md-nav__item ><a href="#Let’s-Learn-More-dask!" class=md-nav__link >Let’s Learn More dask!</a> <li class=md-nav__item ><a href="#There-is-no-magic-here" class=md-nav__link >There is no magic here</a> <li class=md-nav__item ><a href="#Lazy-Evaluation-and-Caching" class=md-nav__link >Lazy Evaluation and Caching</a> <li class=md-nav__item ><a href="#dask-versus-Spark-/-PySpark" class=md-nav__link >dask versus Spark / PySpark</a> <li class=md-nav__item ><a href="#What-else-can-dask-do?" class=md-nav__link >What else can dask do?</a> <li class=md-nav__item ><a href="#What-can’t-dask-do?" class=md-nav__link >What can’t dask do?</a> <li class=md-nav__item ><a href="#If-you-really-want-to-get-into-dask…" class=md-nav__link >If you really want to get into dask…</a> <li class=md-nav__item ><a href="#Exercises" class=md-nav__link >Exercises</a> </ul> </nav> </ul> </nav> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Git and Github</span></span> <li class=md-nav__item > <a href=git_and_github.html  class=md-nav__link >Git and Github</a> <li class=md-nav__item > <a href=pr_review.html  class=md-nav__link >Reviewing Code on Github</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >GIS</span></span> <li class=md-nav__item > <a href=gis_what_is_gis.html  class=md-nav__link >What is GIS?</a> <li class=md-nav__item > <a href=gis_setup_geopandas.html  class=md-nav__link >Installing Geopandas</a> <li class=md-nav__item > <a href=gis_geopandas.html  class=md-nav__link >Geopandas</a> <li class=md-nav__item > <a href=gis_spatial_joins.html  class=md-nav__link >Merging Spatial Data</a> <li class=md-nav__item > <a href=gis_data.html  class=md-nav__link >Spatial Data Formats</a> <li class=md-nav__item > <a href=gis_projections.html  class=md-nav__link >Spatial Projections</a> <li class=md-nav__item > <a href=gis_crs_geopandas.html  class=md-nav__link >Managing Projections in Geopandas</a> <li class=md-nav__item > <a href=gis_mapping.html  class=md-nav__link >Mapping with Geopandas</a> <li class=md-nav__item > <span class="md-nav__link caption"><span class=caption-text >Other</span></span> <li class=md-nav__item > <a href=buying_datascience_computer.html  class=md-nav__link >Buying a Data Science Computer</a> <li class=md-nav__item > <a href=not_a_mids_student.html  class=md-nav__link >Not a MIDS Student?</a> <li class=md-nav__item > <a href=cheatsheets.html  class=md-nav__link >Cheat Sheets</a> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc > <div class=md-sidebar__scrollwrap > <div class=md-sidebar__inner > <nav class="md-nav md-nav--secondary"> <label class=md-nav__title  for=__toc >Contents</label> <ul class=md-nav__list  data-md-scrollfix=""> <li class=md-nav__item ><a href="#distributed-computing--page-root" class=md-nav__link >Distributed Computing with dask</a><nav class=md-nav > <ul class=md-nav__list > <li class=md-nav__item ><a href="#What-can-dask-do-for-me?" class=md-nav__link >What can dask do for me?</a> <li class=md-nav__item ><a href="#“Um…-why-didn’t-you-tell-us-about-this-before?”-I-hear-you-say…" class=md-nav__link >“Um… why didn’t you tell us about this before?” I hear you say…</a> <li class=md-nav__item ><a href="#Vocabulary" class=md-nav__link >Vocabulary</a> <li class=md-nav__item ><a href="#Let’s-Learn-More-dask!" class=md-nav__link >Let’s Learn More dask!</a> <li class=md-nav__item ><a href="#There-is-no-magic-here" class=md-nav__link >There is no magic here</a> <li class=md-nav__item ><a href="#Lazy-Evaluation-and-Caching" class=md-nav__link >Lazy Evaluation and Caching</a> <li class=md-nav__item ><a href="#dask-versus-Spark-/-PySpark" class=md-nav__link >dask versus Spark / PySpark</a> <li class=md-nav__item ><a href="#What-else-can-dask-do?" class=md-nav__link >What else can dask do?</a> <li class=md-nav__item ><a href="#What-can’t-dask-do?" class=md-nav__link >What can’t dask do?</a> <li class=md-nav__item ><a href="#If-you-really-want-to-get-into-dask…" class=md-nav__link >If you really want to get into dask…</a> <li class=md-nav__item ><a href="#Exercises" class=md-nav__link >Exercises</a> </ul> </nav> </ul> </nav> </div> </div> </div> <div class=md-content > <article class="md-content__inner md-typeset" role=main > <style> /* CSS for nbsphinx extension */ /* remove conflicting styling from Sphinx themes */ div.nbinput.container div.prompt *, div.nboutput.container div.prompt *, div.nbinput.container div.input_area pre, div.nboutput.container div.output_area pre, div.nbinput.container div.input_area .highlight, div.nboutput.container div.output_area .highlight { border: none; padding: 0; margin: 0; box-shadow: none; } div.nbinput.container > div[class*=highlight], div.nboutput.container > div[class*=highlight] { margin: 0; } div.nbinput.container div.prompt *, div.nboutput.container div.prompt * { background: none; } div.nboutput.container div.output_area .highlight, div.nboutput.container div.output_area pre { background: unset; } div.nboutput.container div.output_area div.highlight { color: unset; /* override Pygments text color */ } /* avoid gaps between output lines */ div.nboutput.container div[class*=highlight] pre { line-height: normal; } /* input/output containers */ div.nbinput.container, div.nboutput.container { display: -webkit-flex; display: flex; align-items: flex-start; margin: 0; width: 100%; } @media (max-width: 540px) { div.nbinput.container, div.nboutput.container { flex-direction: column; } } /* input container */ div.nbinput.container { padding-top: 5px; } /* last container */ div.nblast.container { padding-bottom: 5px; } /* input prompt */ div.nbinput.container div.prompt pre { color: #307FC1; } /* output prompt */ div.nboutput.container div.prompt pre { color: #BF5B3D; } /* all prompts */ div.nbinput.container div.prompt, div.nboutput.container div.prompt { width: 4.5ex; padding-top: 5px; position: relative; user-select: none; } div.nbinput.container div.prompt > div, div.nboutput.container div.prompt > div { position: absolute; right: 0; margin-right: 0.3ex; } @media (max-width: 540px) { div.nbinput.container div.prompt, div.nboutput.container div.prompt { width: unset; text-align: left; padding: 0.4em; } div.nboutput.container div.prompt.empty { padding: 0; } div.nbinput.container div.prompt > div, div.nboutput.container div.prompt > div { position: unset; } } /* disable scrollbars on prompts */ div.nbinput.container div.prompt pre, div.nboutput.container div.prompt pre { overflow: hidden; } /* input/output area */ div.nbinput.container div.input_area, div.nboutput.container div.output_area { -webkit-flex: 1; flex: 1; overflow: auto; } @media (max-width: 540px) { div.nbinput.container div.input_area, div.nboutput.container div.output_area { width: 100%; } } /* input area */ div.nbinput.container div.input_area { border: 1px solid #e0e0e0; border-radius: 2px; /*background: #f5f5f5;*/ } /* override MathJax center alignment in output cells */ div.nboutput.container div[class*=MathJax] { text-align: left !important; } /* override sphinx.ext.imgmath center alignment in output cells */ div.nboutput.container div.math p { text-align: left; } /* standard error */ div.nboutput.container div.output_area.stderr { background: #fdd; } /* ANSI colors */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } div.nbinput.container div.input_area div[class*=highlight] > pre, div.nboutput.container div.output_area div[class*=highlight] > pre, div.nboutput.container div.output_area div[class*=highlight].math, div.nboutput.container div.output_area.rendered_html, div.nboutput.container div.output_area > div.output_javascript, div.nboutput.container div.output_area:not(.rendered_html) > img{ padding: 5px; margin: 0; } /* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */ div.nbinput.container div.input_area > div[class^='highlight'], div.nboutput.container div.output_area > div[class^='highlight']{ overflow-y: hidden; } /* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */ .prompt .copybtn { display: none; } /* Some additional styling taken form the Jupyter notebook CSS */ .jp-RenderedHTMLCommon table, div.rendered_html table { border: none; border-collapse: collapse; border-spacing: 0; color: black; font-size: 12px; table-layout: fixed; } .jp-RenderedHTMLCommon thead, div.rendered_html thead { border-bottom: 1px solid black; vertical-align: bottom; } .jp-RenderedHTMLCommon tr, .jp-RenderedHTMLCommon th, .jp-RenderedHTMLCommon td, div.rendered_html tr, div.rendered_html th, div.rendered_html td { text-align: right; vertical-align: middle; padding: 0.5em 0.5em; line-height: normal; white-space: normal; max-width: none; border: none; } .jp-RenderedHTMLCommon th, div.rendered_html th { font-weight: bold; } .jp-RenderedHTMLCommon tbody tr:nth-child(odd), div.rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .jp-RenderedHTMLCommon tbody tr:hover, div.rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } </style> <section id=Distributed-Computing-with-dask > <h1 id=distributed-computing--page-root >Distributed Computing with dask<a class=headerlink  href="#distributed-computing--page-root" title="Permalink to this heading">¶</a></h1> <p>In this portion of the course, we’ll explore distributed computing with a Python library called <code class="docutils literal notranslate"><span class=pre >dask</span></code>.</p> <p>dask is a library designed to help facilitate (a) manipulation of very large datasets, and (b) distribution of computation across lots of cores or physical computers. It is very similar to Apache Spark in the functionality it provides, but it is tightly integrated into <code class="docutils literal notranslate"><span class=pre >numpy</span></code> and <code class="docutils literal notranslate"><span class=pre >pandas</span></code>, making it <em>much</em> easier to learn than spark for users of those libraries.</p> <section id="What-can-dask-do-for-me?"> <h2 id="What-can-dask-do-for-me?">What can dask do for me?<a class=headerlink  href="#What-can-dask-do-for-me?" title="Permalink to this heading">¶</a></h2> <p>To get a sense of why dask is so nice, let’s begin with a demonstration. Suppose I have a pretty big dataset (say, <a class="reference external" href="https://www.washingtonpost.com/graphics/2019/investigations/dea-pain-pill-database/">an 80GB CSV of all drug shipments in the United States from 2006 to 2012</a>). This data is too large for me to load into ram on my laptop directly, so if I were to work with it on my own, I’d do so by <a class="reference internal" href=big_data_strategies.html ><span class=doc >chunking the data by hand</span></a>. But using dask, I can do the following:</p> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[1]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Standard setups</span>
<span class=o >%</span><span class=k >load_ext</span> lab_black
<span class=kn >import</span> <span class=nn >pandas</span> <span class=k >as</span> <span class=nn >pd</span>
<span class=kn >import</span> <span class=nn >os</span>

<span class=n >os</span><span class=o >.</span><span class=n >chdir</span><span class=p >(</span><span class=s2 >"/users/nick/github/practicaldatascience/example_data/dask_data"</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[2]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Here we start up a dask cluster.</span>
<span class=c1 ># This creates a set of "workers".</span>
<span class=c1 ># In this case, these workers are all on</span>
<span class=c1 ># my computer, but if we wanted to connect</span>
<span class=c1 ># to a cluster, we'd just past an IP address</span>
<span class=c1 ># to `Client()` (the `n_workers` specifies</span>
<span class=c1 ># the number of workers, so here I use 14).</span>

<span class=c1 ># You can see how many cores your computer</span>
<span class=c1 ># has using `os.cpu_count()` in the `os` library.</span>

<span class=c1 ># Note you may get some warnings about</span>
<span class=c1 ># Python wanting to accept incoming</span>
<span class=c1 ># connections from your firewall.</span>
<span class=c1 ># You need to approve those</span>
<span class=c1 ># so workers can talk to one another.</span>

<span class=kn >import</span> <span class=nn >os</span>

<span class=nb >print</span><span class=p >(</span><span class=s2 >"I have {os.cpu_count()} logical cores, counting hyperthreading."</span><span class=p >)</span>

<span class=kn >from</span> <span class=nn >dask.distributed</span> <span class=kn >import</span> <span class=n >Client</span>

<span class=n >client</span> <span class=o >=</span> <span class=n >Client</span><span class=p >(</span><span class=n >n_workers</span><span class=o >=</span><span class=mi >14</span><span class=p >)</span>
<span class=n >client</span>
</pre></div> </div> </div> <div class="nboutput docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
I have {os.cpu_count()} logical cores, counting hyperthreading.
</pre></div></div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[2]:
</pre></div> </div> <div class="output_area rendered_html docutils container"> <table style="border: 2px solid white;"> <tr> <td style="vertical-align: top; border: 0px solid white"> <h3 style="text-align: left;">Client</h3> <ul style="text-align: left; list-style: none; margin: 0; padding: 0;"> <li><b>Scheduler: </b>tcp://127.0.0.1:52228 <li><b>Dashboard: </b><a href="http://127.0.0.1:8787/status" target=_blank >http://127.0.0.1:8787/status</a> </ul> <td style="vertical-align: top; border: 0px solid white"> <h3 style="text-align: left;">Cluster</h3> <ul style="text-align: left; list-style:none; margin: 0; padding: 0;"> <li><b>Workers: </b>14 <li><b>Cores: </b>28 <li><b>Memory: </b>34.36 GB </ul> </table></div> </div> <div class="nbinput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[3]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># ARCOS Data on all drug shipments in US from 2006 to 2012</span>
<span class=c1 ># I was unable to get this data</span>
<span class=c1 ># into my repo, but you can download it here:</span>
<span class=c1 ># https://d2ty8gaf6rmowa.cloudfront.net/dea-pain-pill-database/bulk/arcos_all_washpost.tsv.gz</span>

<span class=c1 ># Note that while pandas can read compressed files like this .tsv.gz,</span>
<span class=c1 ># file, dask cannot. So if you want to do this at home,</span>
<span class=c1 ># you have to decompress the data.</span>

<span class=kn >import</span> <span class=nn >dask.dataframe</span> <span class=k >as</span> <span class=nn >dd</span>

<span class=n >df</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span>
    <span class=s2 >"arcos_all_washpost.tsv"</span><span class=p >,</span>
    <span class=n >sep</span><span class=o >=</span><span class=s2 >"</span><span class=se >\t</span><span class=s2 >"</span><span class=p >,</span>
    <span class=n >dtype</span><span class=o >=</span><span class=p >{</span>
        <span class=s2 >"ACTION_INDICATOR"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"ORDER_FORM_NO"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"REPORTER_ADDRESS2"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"REPORTER_ADDL_CO_INFO"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"NDC_NO"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"UNIT"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
    <span class=p >},</span>
<span class=p >)</span>
</pre></div> </div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[4]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=c1 ># Extract year</span>
<span class=n >df</span><span class=p >[</span><span class=s2 >"date"</span><span class=p >]</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >to_datetime</span><span class=p >(</span><span class=n >df</span><span class=o >.</span><span class=n >TRANSACTION_DATE</span><span class=p >,</span> <span class=nb >format</span><span class=o >=</span><span class=s2 >"%m</span><span class=si >%d</span><span class=s2 >%Y"</span><span class=p >)</span>
<span class=n >df</span><span class=p >[</span><span class=s2 >"year"</span><span class=p >]</span> <span class=o >=</span> <span class=n >df</span><span class=o >.</span><span class=n >date</span><span class=o >.</span><span class=n >dt</span><span class=o >.</span><span class=n >year</span>

<span class=c1 ># Make an estimate of total morphine equivalent shipments</span>
<span class=n >df</span><span class=p >[</span><span class=s2 >"morphine_equivalent_g"</span><span class=p >]</span> <span class=o >=</span> <span class=p >(</span><span class=n >df</span><span class=p >[</span><span class=s2 >"CALC_BASE_WT_IN_GM"</span><span class=p >])</span> <span class=o >*</span> <span class=n >df</span><span class=p >[</span><span class=s2 >"MME_Conversion_Factor"</span><span class=p >]</span>

<span class=c1 ># Drop extra vars</span>
<span class=n >df</span> <span class=o >=</span> <span class=n >df</span><span class=p >[[</span><span class=s2 >"year"</span><span class=p >,</span> <span class=s2 >"morphine_equivalent_g"</span><span class=p >,</span> <span class=s2 >"BUYER_STATE"</span><span class=p >,</span> <span class=s2 >"BUYER_COUNTY"</span><span class=p >]]</span>

<span class=c1 ># Collapse to total shipments to each county in each year.</span>
<span class=n >collapsed</span> <span class=o >=</span> <span class=n >df</span><span class=o >.</span><span class=n >groupby</span><span class=p >(</span>
    <span class=p >[</span><span class=s2 >"year"</span><span class=p >,</span> <span class=s2 >"BUYER_STATE"</span><span class=p >,</span> <span class=s2 >"BUYER_COUNTY"</span><span class=p >]</span>
<span class=p >)</span><span class=o >.</span><span class=n >morphine_equivalent_g</span><span class=o >.</span><span class=n >sum</span><span class=p >()</span>
<span class=n >collapsed</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[4]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
Dask Series Structure:
npartitions=1
    float64
        ...
Name: morphine_equivalent_g, dtype: float64
Dask Name: series-groupby-sum-agg, 16431 tasks
</pre></div></div> </div> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[5]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=o >%%time</span>
<span class=n >final</span> <span class=o >=</span> <span class=n >collapsed</span><span class=o >.</span><span class=n >compute</span><span class=p >()</span>
<span class=n >final</span><span class=o >.</span><span class=n >sample</span><span class=p >(</span><span class=mi >10</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput docutils container"> <div class="prompt empty docutils container"> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
CPU times: user 43.5 s, sys: 5.72 s, total: 49.2 s
Wall time: 4min 52s
</pre></div></div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[5]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
year  BUYER_STATE  BUYER_COUNTY
2012  UT           UINTAH            8834.433885
2011  UT           UTAH            163675.526524
2007  VA           SALEM            18765.098379
2008  AR           JOHNSON           7609.136588
2010  MD           HARFORD         197344.562986
2012  CO           EL PASO         234048.030580
2010  TN           HENRY            28342.178041
      IA           HANCOCK           1069.664137
2006  AZ           NAVAJO           22462.061395
2007  NY           LEWIS             3651.185006
Name: morphine_equivalent_g, dtype: float64
</pre></div></div> </div> <p>Voila! I get back my thinned out dataset with the new variable I wanted, all while never using more than about 2gb of RAM at any point.</p> <p>So let’s discuss what just happened.</p> <ol class="arabic simple"> <li><p>First, when I ran <code class="docutils literal notranslate"><span class=pre >Client()</span></code>, dask started up a set of 14 new python processes on my computer (called “workers”) it could call on for help. These are fully independent agents that <em>could</em> be running on different machines in a true cluster (though in this case, they’re all on my laptop).</p> <li><p>It then collected all the instructions I gave it for reading in the file, generating a new column, deleting extra columns, and grouping. <strong>But it didn’t actually execute any code</strong>. That’s why when I typed <code class="docutils literal notranslate"><span class=pre >collapsed</span></code>, what I got back was a dataframe with structure but no data – dask had figured out roughly what the result of my commands would look like, but hadn’t actually computed the result.</p> <li><p>Then, when I ran <code class="docutils literal notranslate"><span class=pre >collapsed.compute()</span></code>, dask came up with a set of assignments it could give to its workers to get me what I wanted and it started to actually compute the table I requested. In particular:</p> <ul class=simple > <li><p>each worker loaded a chunk of the data, did the observation-level manipulations I wanted, and dropped extra columns.</p> <li><p>then to execute the groupby, it then collapsed the data in each chunk, passed those collapsed chunks to a common worker who then re-collapsed them further, then gathered them again under (potentially) another worker and collapsed further until all the data had been collapsed.</p> <li><p>Finally, after all the data had been collapsed, the data was passed back to me (the client session) as the variable <code class="docutils literal notranslate"><span class=pre >final</span></code>.</p> </ul> </ol> <p>And it did it all in 5 minutes!</p> </section> <section id="“Um…-why-didn’t-you-tell-us-about-this-before?”-I-hear-you-say…"> <h2 id="“Um…-why-didn’t-you-tell-us-about-this-before?”-I-hear-you-say…">“Um… why didn’t you tell us about this before?” I hear you say…<a class=headerlink  href="#“Um…-why-didn’t-you-tell-us-about-this-before?”-I-hear-you-say…" title="Permalink to this heading">¶</a></h2> <p>“This sure seems like this is easier than <a class="reference external" href=big_data_strategies >chunking by hand</a>!!!!”</p> <p>The answer is that these distributed computing tools are often very fragile and opaque, and it’s easy to get in trouble using them, and hard to figure out why if you don’t understand the underlying principles that govern their operation.</p> <p>This example was carefully chosen. I used only manipulations that dask is really good at, and I have the experience to implement them in a way that works. But do what I did above in slightly different ways, and chaos would ensure. Ok, not chaos. But you’re computer would probably crash.</p> <p>The biggest challenge in using a tool like dask or <code class="docutils literal notranslate"><span class=pre >spark</span></code> (they operate on the same principles – more on that below) is that to prevent crashes, you have to understand how and why dask is chunking your data. And the best way to do that is to get experience chunking by hand.</p> <p>For example, one of the key features of distributing computing is that they don’t run code as soon as you type it. Instead, they just keep track of what you want and wait until you run <code class="docutils literal notranslate"><span class=pre >.compute()</span></code> to actually execute your code. Why? Because if dask had run each command as I entered it and passed the result back to me, it would have crashed my computer.</p> <p>Recall that the whole reason we’re using dask is precisely because we knew that loading the whole dataset at once would take up more memory than I have available. It’s only because we only loaded a few chunks of the data at a time, thinned out those chunks by dropping variables, and then collapsed by county-state-year that we ended up with a dataset that was small enough that it would fit in memory.</p> <p>In other words, this only worked because I knew that the steps after the intial load would reduce the size of the dataset enough that when I ran <code class="docutils literal notranslate"><span class=pre >.compute()</span></code>, the result I got back would be small enough to fit in memory. Had I just run:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=n >df</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span><span class=s1 >'arcos_all_washpost.tsv'</span><span class=p >,</span> <span class=n >sep</span><span class=o >=</span><span class=s1 >'</span><span class=se >\t</span><span class=s1 >'</span><span class=p >,</span>
                <span class=n >dtype</span><span class=o >=</span><span class=p >{</span><span class=s1 >'ACTION_INDICATOR'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'ORDER_FORM_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDRESS2'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDL_CO_INFO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'NDC_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'UNIT'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >})</span>
<span class=n >df</span><span class=o >.</span><span class=n >compute</span><span class=p >()</span>
</pre></div> </div> <p>dask would have tried to hand the full dataset back to me, and my computer would have crashed, just as it would had I tried to read the full dataset with <code class="docutils literal notranslate"><span class=pre >pandas</span></code>.</p> <p>So understanding the <em>intuition</em> of chunking is basically a pre-requisite to using these tools effectively.</p> </section> <section id=Vocabulary > <h2 id=Vocabulary >Vocabulary<a class=headerlink  href="#Vocabulary" title="Permalink to this heading">¶</a></h2> <p>Now that we’ve seen this example, let’s formally introduce some distributed computing vocabulary:</p> <ul class=simple > <li><p><strong>Lazy Evaluation</strong> (also sometimes called “delayed execution”): The practice of not executing code as soon as you type it, but rather accumulating a set of requests, then executing them when instructed. This allows distributing computing systems to optimize how they move around data and get things done, and ensures that you don’t end up with the system trying to shove a massive dataset into ram that’s too small.</p> <li><p><strong>Client</strong>: The central process (here, Python process) where code is being entered.</p> <li><p><strong>Workers</strong>: Other processes that are assigned work, and which eventually pass results back to the client.</p> <li><p><strong>Scheduler</strong>: The part of the system that manages the assignment of tasks to different workers.</p> <li><p><strong>map-reduce</strong>: The name for the process of distributing sub-problems to workers (<code class="docutils literal notranslate"><span class=pre >map</span></code>), then processing them in a way that allows the results to be recombined (<code class="docutils literal notranslate"><span class=pre >reduce</span></code>). <code class="docutils literal notranslate"><span class=pre >map</span></code>s and <code class="docutils literal notranslate"><span class=pre >reduce</span></code>s are kind of the building blocks of distributed systems, though when working with dask you won’t usually have to manage the assignment or recombination of tasks yourself (they’re happening behind the scenes).</p> </ul> </section> <section id="Let’s-Learn-More-dask!"> <h2 id="Let’s-Learn-More-dask!">Let’s Learn More dask!<a class=headerlink  href="#Let’s-Learn-More-dask!" title="Permalink to this heading">¶</a></h2> <p>OK, now that we have the basic idea of dask in hand, please watch the following (<em>very</em> well organized) talk on dask. Then come back here and we can talk some more!</p> <p><a class="reference external" href="https://www.youtube.com/watch?v=RA_2qdipVng">Matthew Rocklin on Dask</a></p> </section> <section id=There-is-no-magic-here > <h2 id=There-is-no-magic-here >There is no magic here<a class=headerlink  href="#There-is-no-magic-here" title="Permalink to this heading">¶</a></h2> <p>As noted in that video, one of the very nice things about dask (and one of the reasons it’s been able to offer so much functionality so quickly) is that it really is just an extension of <code class="docutils literal notranslate"><span class=pre >numpy</span></code> and <code class="docutils literal notranslate"><span class=pre >pandas</span></code>. There is no magic here.</p> <p>For example, suppose we wanted to find the largest number of pills in a single shipment in our ARCOS dataset, but we don’t have the memory to load the whole dataset into memory at once. How would we get that number? Probably by doing something like:</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[6]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=kn >import</span> <span class=nn >pandas</span> <span class=k >as</span> <span class=nn >pd</span>
<span class=kn >import</span> <span class=nn >numpy</span> <span class=k >as</span> <span class=nn >np</span>
<span class=kn >import</span> <span class=nn >os</span>

<span class=n >os</span><span class=o >.</span><span class=n >chdir</span><span class=p >(</span><span class=s2 >"/users/nick/github/practicaldatascience/example_data/dask_data"</span><span class=p >)</span>

<span class=c1 ># Create an interator of the data so</span>
<span class=c1 ># it doesn't all load at once</span>
<span class=n >df</span> <span class=o >=</span> <span class=n >pd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span>
    <span class=s2 >"arcos_all_washpost.tsv"</span><span class=p >,</span>
    <span class=n >delimiter</span><span class=o >=</span><span class=s2 >"</span><span class=se >\t</span><span class=s2 >"</span><span class=p >,</span>
    <span class=n >iterator</span><span class=o >=</span><span class=kc >True</span><span class=p >,</span>
    <span class=n >chunksize</span><span class=o >=</span><span class=mi >100000</span><span class=p >,</span>
    <span class=n >usecols</span><span class=o >=</span><span class=p >[</span><span class=s2 >"DOSAGE_UNIT"</span><span class=p >,</span> <span class=s2 >"Measure"</span><span class=p >],</span>
<span class=p >)</span>


<span class=c1 ># Find the max from each chunk</span>
<span class=n >max_candidates</span> <span class=o >=</span> <span class=nb >list</span><span class=p >()</span>
<span class=k >for</span> <span class=n >chunk</span> <span class=ow >in</span> <span class=n >df</span><span class=p >:</span>
    <span class=c1 ># Subset for pill shipments</span>
    <span class=n >chunk</span> <span class=o >=</span> <span class=n >chunk</span><span class=p >[</span><span class=n >chunk</span><span class=p >[</span><span class=s2 >"Measure"</span><span class=p >]</span> <span class=o >==</span> <span class=s2 >"TAB"</span><span class=p >]</span>

    <span class=c1 ># Find largest in this chunk</span>
    <span class=n >max_candidates</span><span class=o >.</span><span class=n >append</span><span class=p >(</span><span class=n >chunk</span><span class=p >[</span><span class=s2 >"DOSAGE_UNIT"</span><span class=p >]</span><span class=o >.</span><span class=n >max</span><span class=p >())</span>

<span class=c1 ># Now gather those candidates together and</span>
<span class=c1 ># find the maximum of all the chunk maximums.</span>
<span class=n >np</span><span class=o >.</span><span class=n >max</span><span class=p >(</span><span class=n >max_candidates</span><span class=p >)</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[6]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
3115000.0
</pre></div></div> </div> <p>Wow… that is a LOT of pills!</p> <p>Now suppose we asked dask to do the same thing:</p> <div class="nbinput docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[7]:
</pre></div> </div> <div class="input_area highlight-ipython3 notranslate"><div class=highlight ><pre><span></span><span class=n >df</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span>
    <span class=s2 >"arcos_all_washpost.tsv"</span><span class=p >,</span>
    <span class=n >sep</span><span class=o >=</span><span class=s2 >"</span><span class=se >\t</span><span class=s2 >"</span><span class=p >,</span>
    <span class=n >dtype</span><span class=o >=</span><span class=p >{</span>
        <span class=s2 >"ACTION_INDICATOR"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"ORDER_FORM_NO"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"REPORTER_ADDRESS2"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"REPORTER_ADDL_CO_INFO"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"NDC_NO"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
        <span class=s2 >"UNIT"</span><span class=p >:</span> <span class=s2 >"object"</span><span class=p >,</span>
    <span class=p >},</span>
<span class=p >)</span>

<span class=n >df</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=n >df</span><span class=p >[</span><span class=s2 >"Measure"</span><span class=p >]</span> <span class=o >==</span> <span class=s2 >"TAB"</span><span class=p >]</span>
<span class=n >max_shipment</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=s2 >"DOSAGE_UNIT"</span><span class=p >]</span><span class=o >.</span><span class=n >max</span><span class=p >()</span>
<span class=n >max_shipment</span><span class=o >.</span><span class=n >compute</span><span class=p >()</span>
</pre></div> </div> </div> <div class="nboutput nblast docutils container"> <div class="prompt highlight-none notranslate"><div class=highlight ><pre><span></span>[7]:
</pre></div> </div> <div class="output_area docutils container"> <div class=highlight ><pre>
3115000.0
</pre></div></div> </div> <p>What dask is actually doing is exactly what you just did! It reads in chunks of the dataset, calculates <code class="docutils literal notranslate"><span class=pre >morphine_equivalent_g</span></code> for each chunk, then calculates the maximum value for that chunk. Then it gathers all those maximium values, and finds the maximum of all those chunk maximums. The only difference is that it loads and evaluations chunks in parallel, and it’s parallel workers then have to pass their maximum value candidates to a central node for the final evaluation.</p> <p>Moreover, when I said that’s exactly what dask did, I don’t just mean that you and dask are doing the same thing <em>in principle</em> – dask is built on pandas, so it really is calling <code class="docutils literal notranslate"><span class=pre >pd.read_csv</span></code>, and the <code class="docutils literal notranslate"><span class=pre >pandas</span></code> <code class="docutils literal notranslate"><span class=pre >.max()</span></code> method, just like you.</p> <p>Dask’s developers were smart, and didn’t want to reinvent the wheel – they just created a package full or recipes for using numpy/pandas to (a) divide tasks into smaller pieces it can distribute to different workers (map), and to (b) recombine the results of sub-problems to give you a single answer (reduce).</p> <p>But those recipes are just made of the pandas and numpy code you know and love. Or at least tolerate begrudingly.</p> </section> <section id=Lazy-Evaluation-and-Caching > <h2 id=Lazy-Evaluation-and-Caching >Lazy Evaluation and Caching<a class=headerlink  href="#Lazy-Evaluation-and-Caching" title="Permalink to this heading">¶</a></h2> <p>You’ve already seen this above, but I think there are two concepts that are really central to not just dask, but <strong>any</strong> distributed computing platform (e.g. Spark, Hadoop, etc.), so I really want to drive home the importance of these concepts:</p> <p><strong>Lazy Evaluation:</strong> The fact that you can give dask a handful of commands <em>and then</em> tell it to execute them is at the absolute core of what makes it effective. The more commands you can give dask up front, the more it can optimize how it distributes that work – and how it moves data between different computers. Moving data between processes and between computers is <em>by far</em> the slowest part of distributed computing, so the more dask can minimize those transfers, the faster it will be.</p> <p>Moreover, lazy evaluation is how you protect yourself from crashing your computer. Consider the following code:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=n >df</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span><span class=s1 >'arcos_all_washpost.tsv'</span><span class=p >,</span> <span class=n >sep</span><span class=o >=</span><span class=s1 >'</span><span class=se >\t</span><span class=s1 >'</span><span class=p >,</span>
                <span class=n >dtype</span><span class=o >=</span><span class=p >{</span><span class=s1 >'ACTION_INDICATOR'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'ORDER_FORM_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDRESS2'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDL_CO_INFO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'NDC_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'UNIT'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >})</span>

<span class=n >df</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=n >df</span><span class=p >[</span><span class=s1 >'Measure'</span><span class=p >]</span> <span class=o >==</span> <span class=s2 >"TAB"</span><span class=p >]</span>
<span class=n >df</span><span class=o >.</span><span class=n >compute</span><span class=p >()</span>
</pre></div> </div> <p>If <code class="docutils literal notranslate"><span class=pre >dd.read_csv()</span></code> executed immediately and tried to load all the data and pass it back to you before subsetting, it’d crash your computer! After all, if you could load it all at once, we probably wouldn’t be using dask, would we? It’s only because dask knows you want to load each chunk then subset it before collecting all those pieces that this code works.</p> <p><strong>Caching:</strong> Another important concept in distributed computing is caching. Consider the following code:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=n >df</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span><span class=s1 >'arcos_all_washpost.tsv'</span><span class=p >,</span> <span class=n >sep</span><span class=o >=</span><span class=s1 >'</span><span class=se >\t</span><span class=s1 >'</span><span class=p >,</span>
                <span class=n >dtype</span><span class=o >=</span><span class=p >{</span><span class=s1 >'ACTION_INDICATOR'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'ORDER_FORM_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDRESS2'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDL_CO_INFO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'NDC_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'UNIT'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >})</span>

<span class=n >df</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=n >df</span><span class=p >[</span><span class=s1 >'Measure'</span><span class=p >]</span> <span class=o >==</span> <span class=s2 >"TAB"</span><span class=p >]</span>
<span class=n >max_shipment</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'DOSAGE_UNIT'</span><span class=p >]</span><span class=o >.</span><span class=n >max</span><span class=p >()</span>
<span class=n >max_shipment</span><span class=o >.</span><span class=n >compute</span><span class=p >()</span>

<span class=n >df</span><span class=p >[</span><span class=s1 >'morphine_equivalent_g'</span><span class=p >]</span> <span class=o >=</span> <span class=p >(</span><span class=n >df</span><span class=p >[</span><span class=s1 >'CALC_BASE_WT_IN_GM'</span><span class=p >])</span> <span class=o >*</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'MME_Conversion_Factor'</span><span class=p >])</span>
<span class=n >mean_shipment</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'morphine_equivalent_g'</span><span class=p >]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span>
<span class=n >mean_shipment</span><span class=o >.</span><span class=n >compute</span><span class=p >()</span>
</pre></div> </div> <p>If you ran this code, then when dask got to the first compute (<code class="docutils literal notranslate"><span class=pre >max_shipment.compute()</span></code>), it would run the recipe up to that point and return <code class="docutils literal notranslate"><span class=pre >max_shipment</span></code>. Great. But in the process, it would be throwing away any data it didn’t need. Because at the moment it got to <code class="docutils literal notranslate"><span class=pre >max_shipment.compute()</span></code> it doesn’t yet know you’ll want more analysies on this same data. As a result, when you got down to the <em>second</em> compute call (<code class="docutils literal notranslate"><span class=pre >mean_shipment.compute()</span></code>), dask would have to start over and re-load the data all over again. Since loading data is <em>very</em> slow, this would be hugely wasteful.</p> <p>There are two ways to get around this. The first is to combine the two requests into a single compute call so it knows, when it starts running code, that you’ll gonna want both <code class="docutils literal notranslate"><span class=pre >max_shipment</span></code> and <code class="docutils literal notranslate"><span class=pre >mean_shipment</span></code>, like this:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=n >df</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span><span class=s1 >'arcos_all_washpost.tsv'</span><span class=p >,</span> <span class=n >sep</span><span class=o >=</span><span class=s1 >'</span><span class=se >\t</span><span class=s1 >'</span><span class=p >,</span>
                <span class=n >dtype</span><span class=o >=</span><span class=p >{</span><span class=s1 >'ACTION_INDICATOR'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'ORDER_FORM_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDRESS2'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDL_CO_INFO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'NDC_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'UNIT'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >})</span>

<span class=n >df</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=n >df</span><span class=p >[</span><span class=s1 >'Measure'</span><span class=p >]</span> <span class=o >==</span> <span class=s2 >"TAB"</span><span class=p >]</span>
<span class=n >max_shipment</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'DOSAGE_UNIT'</span><span class=p >]</span><span class=o >.</span><span class=n >max</span><span class=p >()</span>

<span class=n >df</span><span class=p >[</span><span class=s1 >'morphine_equivalent_g'</span><span class=p >]</span> <span class=o >=</span> <span class=p >(</span><span class=n >df</span><span class=p >[</span><span class=s1 >'CALC_BASE_WT_IN_GM'</span><span class=p >])</span> <span class=o >*</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'MME_Conversion_Factor'</span><span class=p >])</span>
<span class=n >mean_shipment</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'morphine_equivalent_g'</span><span class=p >]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span>

<span class=n >max_ship</span><span class=p >,</span> <span class=n >mean_ship</span> <span class=o >=</span> <span class=n >dask</span><span class=o >.</span><span class=n >compute</span><span class=p >(</span><span class=n >max_shipment</span><span class=p >,</span> <span class=n >mean_shipment</span><span class=p >)</span>
</pre></div> </div> <p>But requires you know in advance everything you want, and one of the best parts of dask is you can use it for data exploration, just like regular pandas. So the other option is to tell it to not throw away <code class="docutils literal notranslate"><span class=pre >df</span></code> right away when it’s done calculating <code class="docutils literal notranslate"><span class=pre >max_shipment</span></code>! This is what is known as “caching” a result, and can be accomplished with the command <code class="docutils literal notranslate"><span class=pre >.persist()</span></code></p> <p>So in this case, we know there’s a <em>lot</em> of working happening to load the data and subset it, so let’s as dask to cache that sub-set dataset:</p> <div class="highlight-python notranslate"><div class=highlight ><pre><span></span><span class=n >df</span> <span class=o >=</span> <span class=n >dd</span><span class=o >.</span><span class=n >read_csv</span><span class=p >(</span><span class=s1 >'arcos_all_washpost.tsv'</span><span class=p >,</span> <span class=n >sep</span><span class=o >=</span><span class=s1 >'</span><span class=se >\t</span><span class=s1 >'</span><span class=p >,</span>
                <span class=n >dtype</span><span class=o >=</span><span class=p >{</span><span class=s1 >'ACTION_INDICATOR'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'ORDER_FORM_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDRESS2'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'REPORTER_ADDL_CO_INFO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'NDC_NO'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >,</span>
                       <span class=s1 >'UNIT'</span><span class=p >:</span> <span class=s1 >'object'</span><span class=p >})</span>

<span class=n >df</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=n >df</span><span class=p >[</span><span class=s1 >'Measure'</span><span class=p >]</span> <span class=o >==</span> <span class=s2 >"TAB"</span><span class=p >]</span>

<span class=n >df</span> <span class=o >=</span> <span class=n >df</span><span class=o >.</span><span class=n >persist</span><span class=p >()</span> <span class=c1 ># When you calculate `df` the first time</span>
                  <span class=c1 ># hang on to it for later!</span>
                  <span class=c1 ># Note you hvae to use `df = df.persist(),</span>
                  <span class=c1 ># note just `df.persist()`.</span>

<span class=n >max_shipment</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'DOSAGE_UNIT'</span><span class=p >]</span><span class=o >.</span><span class=n >max</span><span class=p >()</span>

<span class=n >df</span><span class=p >[</span><span class=s1 >'morphine_equivalent_g'</span><span class=p >]</span> <span class=o >=</span> <span class=p >(</span><span class=n >df</span><span class=p >[</span><span class=s1 >'CALC_BASE_WT_IN_GM'</span><span class=p >])</span> <span class=o >*</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'MME_Conversion_Factor'</span><span class=p >])</span>
<span class=n >mean_shipment</span> <span class=o >=</span> <span class=n >df</span><span class=p >[</span><span class=s1 >'morphine_equivalent_g'</span><span class=p >]</span><span class=o >.</span><span class=n >mean</span><span class=p >()</span>

<span class=n >max_ship</span><span class=p >,</span> <span class=n >mean_ship</span> <span class=o >=</span> <span class=n >dask</span><span class=o >.</span><span class=n >compute</span><span class=p >(</span><span class=n >max_shipment</span><span class=p >,</span> <span class=n >mean_shipment</span><span class=p >)</span>
</pre></div> </div> </section> <section id="dask-versus-Spark-/-PySpark"> <h2 id="dask-versus-Spark-/-PySpark">dask versus Spark / PySpark<a class=headerlink  href="#dask-versus-Spark-/-PySpark" title="Permalink to this heading">¶</a></h2> <p>dask is something of a late-comer to the distributed computing game. Before its rise the most popular platforms were Hadoop and Spark (which is kinda Hadoop v2.0). So… how does dask compare to these? Or more specifically, how does dask compare to Spark (since no one uses Hadoop any more) and the Python library for using Spark (PySpark)?</p> <p>In terms of funcationality, dask and Spark basically do the same things. Both are tools for distributed computing across many computers, and conceptually they work in basically the same ways:</p> <ul class=simple > <li><p>Both offer both low-level tools (things like <code class="docutils literal notranslate"><span class=pre >map</span></code>/<code class="docutils literal notranslate"><span class=pre >filter</span></code> in pyspark, and <code class="docutils literal notranslate"><span class=pre >delayed</span></code> in dask) as well as higher-level abstractions (<code class="docutils literal notranslate"><span class=pre >spark</span></code> has <code class="docutils literal notranslate"><span class=pre >spark</span> <span class=pre >dataframes</span></code>, dask has <code class="docutils literal notranslate"><span class=pre >dask</span> <span class=pre >arrays</span></code>; <code class="docutils literal notranslate"><span class=pre >spark</span></code> has RDDs, dask has <code class="docutils literal notranslate"><span class=pre >dask</span> <span class=pre >arrays</span></code>).</p> <li><p>Both are fault tolerate (if one machine in your cluster dies, the system knows what the machine that died was doing and can assign it to another cluster).</p> <li><p>Both make use of delayed execution / lazy evaluation to allow the system to develop efficient plans for completing a computation efficiently.</p> <li><p>Both can be run both on your own computer, or on a cluster of lots of computers.</p> </ul> <p><strong>The huge difference, though, is that dask lets you write code with the pandas syntax you already know.</strong> Seriously. There are lots of little “under the hood” things, but from the perspective of an applied Data Scientist, that’s the big one: it’s just Python.</p> <p>Moreover, as we’ll see in <a class="reference internal" href=cloud_dask.html ><span class=doc >later lessons</span></a>, dask is also insanely easy to setup on a distributed cluster, making it not only easier to use than Spark for a pandas users, but generally also much easier to get up and running.</p> <p>Spark, by contrast, is a stand-alone system. It’s built to run on Java virtual machines, and Spark itself is written in a language called Scala. It is not a tool for pandas users per se, and so it has its own syntax for manipulating datasets that is distinct from that of <code class="docutils literal notranslate"><span class=pre >numpy</span></code> and <code class="docutils literal notranslate"><span class=pre >pandas</span></code>.</p> <p>As for which is more popular, as is so often the case with software, it depends on where you’re working. In this class, I’ve decided to teach dask because you don’t have to learn a new syntax, so you can instead just focus on learning how distributed computing works. But if you get a job someday that requires you to work with Spark, don’t panic – you’ll find that all the concepts you’ve learned for using dask also apply to Spark – you’ll just have to learn some new syntax.</p> <p>And as for performance, it probably depends on the workload, but I’ve yet to see anything that suggests dask compute times are slower than Spark compute times. Case studies are always tricky since performance depends on the exact work being done, but here’s one <a class="reference external" href="https://arxiv.org/abs/1907.13030">case study comparison of performance</a> that puts dask just a little ahead. And I’ve heard reports of dask beating Spark by 40x in another project. So personally, I think dask is a no brainer: it will take <strong>much</strong> less of your time setup and use, and it should at least run about even with Spark.</p> <p>The only exceptions are some specific use cases, like network analysis, where Spark has some libraries that dask does not. For more on these types of issues, check out this <a class="reference external" href="https://docs.dask.org/en/latest/spark.html">conceptual comparison to Spark</a>.</p> </section> <section id="What-else-can-dask-do?"> <h2 id="What-else-can-dask-do?">What else can dask do?<a class=headerlink  href="#What-else-can-dask-do?" title="Permalink to this heading">¶</a></h2> <p>At this point, we’ve mostly emphasized what dask can do in terms of the data wrangling of dataframes. However, dask has a number of additional functionalities to be aware of:</p> <ul class=simple > <li><p>Working with dask arrays: dask has a parallelized version of numpy arrays</p> <li><p>Parallelizing arbitrary functions: you can write your own parallelized functions with <code class="docutils literal notranslate"><span class=pre >delayed</span></code></p> <li><p>Distributed machine learning: dask has parallelized SOME machine learning methods in <a class="reference external" href="https://dask-ml.readthedocs.io/en/latest/">dask-ml</a></p> <li><p>dask can be used with different tools for parallelization other than <code class="docutils literal notranslate"><span class=pre >distributed</span></code> (for example, it can do some parallelism through multi-threading). However… it seems like everyone seems to agree at this point you should just use <code class="docutils literal notranslate"><span class=pre >distributed</span></code> all the time.</p> </ul> </section> <section id="What-can’t-dask-do?"> <h2 id="What-can’t-dask-do?">What can’t dask do?<a class=headerlink  href="#What-can’t-dask-do?" title="Permalink to this heading">¶</a></h2> <p>Because dask is basically a library full of little recipes for parallelizing common python, numpy, and pandas functions, you will occassionally find that there are some things that the authors of dask just haven’t implemented (usually because some operations are <em>really</em> hard to parallelize). Here are guides to what you can expect to work and what is unlikely to work with dask:</p> <ul class=simple > <li><p><a class="reference external" href="https://docs.dask.org/en/latest/dataframe.html#scope">When using dask dataframes</a></p> <li><p><a class="reference external" href="https://docs.dask.org/en/latest/array.html#scope">When using dask arrays</a></p> </ul> </section> <section id="If-you-really-want-to-get-into-dask…"> <h2 id="If-you-really-want-to-get-into-dask…">If you really want to get into dask…<a class=headerlink  href="#If-you-really-want-to-get-into-dask…" title="Permalink to this heading">¶</a></h2> <p>Then <em>after</em> doing the exercise below (which I think is actually the most accessible to those taking this class), here are some extensions and next steps:</p> <ul class=simple > <li><p>First, be sure to check out <a class="reference external" href="https://docs.dask.org/en/latest/best-practices.html">dask best practices here</a>.</p> <li><p><code class="docutils literal notranslate"><span class=pre >dask-ml</span></code>: As a reminder, if you now want to do some machine learning, you can <a class="reference external" href="https://ml.dask.org/">use dask-ml on this system</a>, which does the same thing for <code class="docutils literal notranslate"><span class=pre >scikit-learn</span></code> that regular dask does for <code class="docutils literal notranslate"><span class=pre >pandas</span></code>.</p> <li><p>Here’s a great blog post on the <a class="reference external" href="https://coiled.io/blog/history-dask/">history of dask</a> by one of its creaters.</p> <li><p>Interested in using dask in your company and want help? There’s a great new company created by the founders of dask to provide enterprise support for dask <a class="reference external" href="https://coiled.io/">called coiled</a> (No, I have no affiliation with them, I just think these companies that try to offer paid support services to businesses to help them move from closed source software to open source are a great way to help make open source software better). You can also hear a fun interview with the founders about <a class="reference external" href="https://talkpython.fm/episodes/show/285/dask-as-a-platform-service-with-coiled">both dask and coiled here</a>.</p> <li><p>The folks from coiled have also compiled a <a class="reference external" href="https://coiled.io/videos/">great collection of videos and tutorials about dask and Python at scale here</a></p> <li><p>Curious how dask compares to other tools for distributed computing? Here’s a <a class="reference external" href="https://docs.dask.org/en/latest/spark.html">conceptual comparison to Spark</a>, and here’s a <a class="reference external" href="https://arxiv.org/abs/1907.13030">case study comparison of performance</a>. Comparisons will usually depend a lot on the specifics of the work being done, but at least in this case, dask was a little faster than Spark.</p> <li><p>Working with GPUs? There’s a project to offer the kind of CPU parallelization we get from dask for GPUs called <a class="reference external" href="https://docs.rapids.ai/api/cudf/stable/dask-cudf.html">dask-cudf</a> (part of the <a class="reference external" href="https://rapids.ai/index.html">RAPIDS project</a>. The project is young but growing quickly. My guess, though, is that those libraries will become the infrastructure for updates to tools like <code class="docutils literal notranslate"><span class=pre >dask-ml</span></code> rather than something most applied people need to play with. But putting it here as an FYI!</p> </ul> </section> <section id=Exercises > <h2 id=Exercises >Exercises<a class=headerlink  href="#Exercises" title="Permalink to this heading">¶</a></h2> <p>Exercises can be found <a class="reference internal" href="exercises/Exercise_dask.html"><span class=doc >here</span></a></p> <p>If you want more, you can find tutorials written by the dask team <a class="reference external" href="https://github.com/dask/dask-tutorial">here</a>.</p> <p>(Note: all these tutorials are great, but as the focus of this class is on real world tabular data, we’re gonna focus on those exercises).</p> <p><a class="reference internal" href=cheatsheets.html ><span class=doc >When you’re done, you can find a dask cheatsheet here for future reference!</span></a></p> </section> </section> </article> </div> </div> </main> </div> <footer class=md-footer > <div class=md-footer-nav > <nav class="md-footer-nav__inner md-grid"> <a href=parallelism.html  title="Parallel Computing" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel=prev > <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class=md-flex__ellipsis > <span class=md-footer-nav__direction > Previous </span> Parallel Computing </span> </div> </a> <a href=git_and_github.html  title="Git and Github" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel=next > <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span class=md-flex__ellipsis > <span class=md-footer-nav__direction > Next </span> Git and Github </span> </div> <div class="md-flex__cell md-flex__cell--shrink"><i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright > <div class=md-footer-copyright__highlight > &#169; Copyright 2021, Nick Eubank. </div> Created using <a href="http://www.sphinx-doc.org/">Sphinx</a> 5.3.0. and <a href="https://github.com/bashtage/sphinx-material/">Material for Sphinx</a> </div> </div> </div> </footer> <script src="_static/javascripts/application.js"></script> <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>